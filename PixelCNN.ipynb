{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PixelCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMs7sEhUHx5Pboycf9+as9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lee-Gunju/AI-paper-code-review-for-personal-project/blob/master/PixelCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IcZODylw-sg"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKZMBRwFxQKs",
        "outputId": "d2986f52-21ad-40f4-e472-c4291ed8fc52"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "n_residual_blocks = 5\n",
        "\n",
        "# The data, split between train and test sets\n",
        "(x, _), (y, _) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Concatenate all of the images together\n",
        "data = np.concatenate((x, y), axis=0)\n",
        "\n",
        "# Round all pixel values less than 33% of the max 256 value to 0\n",
        "# anything above this value gets rounded up to 1 so that all values are either\n",
        "# 0 or 1\n",
        "\n",
        "data = np.where(data < (0.33 * 256), 0, 1)\n",
        "data = data.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-ASooecxlBK"
      },
      "source": [
        "# The first layer is the PixelCNN layer. This layer simply\n",
        "# builds on the 2D convolutional layer, but includes masking.\n",
        "\n",
        "class PixelConvLayer(layers.Layer):\n",
        "  def __init__(self, mask_type, **kwargs):\n",
        "    super(PixelConvLayer, self).__init__()\n",
        "    self.mask_type = mask_type \n",
        "    self.conv = layers.Conv2D(**kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    # Build the conv2d layer to initialize kernel variables\n",
        "    self.conv.build(input_shape)\n",
        "    # Use the initialized kernel to create the mask\n",
        "    kernel_shape = self.conv.kernel.get_shape()\n",
        "    self.mask = np.zeros(shape = kernel_shape)\n",
        "    self.mask[: kernel_shape[0] // 2, ...] = 1.0 \n",
        "    self.mask[kernel_shape[0] // 2, : kernel_shape[1] //2, ...] = 1.0\n",
        "    if self.mask_type == \"B\":\n",
        "      self.mask[kernel_shape[0] //2, kernel_shape[1] //2, ...] = 1.0 \n",
        "  \n",
        "  def call(self, inputs):\n",
        "    self.conv.kernel.assign(self.conv.kernel * self.mask)\n",
        "    return self.conv(inputs)\n",
        "\n",
        "\n",
        "# Next, we build our residual block layer.\n",
        "# This is just a normal residual block, but based on the PixelConvLayer.\n",
        "class ResidualBlock(keras.layers.Layer):\n",
        "  def __init__(self, filters, **kwargs):\n",
        "    super(ResidualBlock, self).__init__(**kwargs)\n",
        "    self.conv1 = keras.layers.Conv2D(filters = filters, kernel_size= 1, activation='relu')\n",
        "    self.pixel_conv = PixelConvLayer(mask_type = 'B', filters = filters // 2, kernel_size=  3, activation='relu', padding = 'same')\n",
        "    self.conv2 = keras.layers.Conv2D(filters = filters, kernel_size = 1, activation='relu')\n",
        "  def call(self, inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.pixel_conv(x)\n",
        "    x = self.conv2(x)\n",
        "    return keras.layers.add([inputs, x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHt2SAHUxmGq",
        "outputId": "afdcd1e9-73d1-4bcc-d676-4ee285c7a146"
      },
      "source": [
        "inputs = keras.Input(shape=input_shape)\n",
        "x = PixelConvLayer(mask_type = 'A', filters = 128, kernel_size = 7, activation = 'relu', padding = 'same')(inputs)\n",
        "\n",
        "for _ in range(n_residual_blocks):\n",
        "  x = ResidualBlock(filters = 128)(x)\n",
        "\n",
        "for _ in range(2):\n",
        "  x = PixelConvLayer(mask_type='B', filters = 128, kernel_size = 1, strides = 1, activation = 'relu', padding ='same')(x)\n",
        "\n",
        "out = keras.layers.Conv2D(\n",
        "    filters=1, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"valid\"\n",
        ")(x)\n",
        "\n",
        "pixel_cnn = keras.Model(inputs, out)\n",
        "adam = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "pixel_cnn.compile(optimizer=adam, loss=\"binary_crossentropy\")\n",
        "\n",
        "pixel_cnn.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "pixel_conv_layer_3 (PixelCon (None, 28, 28, 128)       6400      \n",
            "_________________________________________________________________\n",
            "residual_block_1 (ResidualBl (None, 28, 28, 128)       98624     \n",
            "_________________________________________________________________\n",
            "residual_block_2 (ResidualBl (None, 28, 28, 128)       98624     \n",
            "_________________________________________________________________\n",
            "residual_block_3 (ResidualBl (None, 28, 28, 128)       98624     \n",
            "_________________________________________________________________\n",
            "residual_block_4 (ResidualBl (None, 28, 28, 128)       98624     \n",
            "_________________________________________________________________\n",
            "residual_block_5 (ResidualBl (None, 28, 28, 128)       98624     \n",
            "_________________________________________________________________\n",
            "pixel_conv_layer_9 (PixelCon (None, 28, 28, 128)       16512     \n",
            "_________________________________________________________________\n",
            "pixel_conv_layer_10 (PixelCo (None, 28, 28, 128)       16512     \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 28, 28, 1)         129       \n",
            "=================================================================\n",
            "Total params: 532,673\n",
            "Trainable params: 532,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXRq4UDCxq6K",
        "outputId": "25b8d428-0266-4d6a-c8f1-fd776fc1b573"
      },
      "source": [
        "pixel_cnn.fit(\n",
        "    x=data, y=data, batch_size=128, epochs=50, validation_split=0.1, verbose=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "493/493 - 64s - loss: 0.1142 - val_loss: 0.0939\n",
            "Epoch 2/50\n",
            "493/493 - 32s - loss: 0.0913 - val_loss: 0.0898\n",
            "Epoch 3/50\n",
            "493/493 - 32s - loss: 0.0893 - val_loss: 0.0884\n",
            "Epoch 4/50\n",
            "493/493 - 32s - loss: 0.0881 - val_loss: 0.0876\n",
            "Epoch 5/50\n",
            "493/493 - 32s - loss: 0.0874 - val_loss: 0.0872\n",
            "Epoch 6/50\n",
            "493/493 - 32s - loss: 0.0868 - val_loss: 0.0864\n",
            "Epoch 7/50\n",
            "493/493 - 32s - loss: 0.0863 - val_loss: 0.0861\n",
            "Epoch 8/50\n",
            "493/493 - 32s - loss: 0.0859 - val_loss: 0.0862\n",
            "Epoch 9/50\n",
            "493/493 - 32s - loss: 0.0856 - val_loss: 0.0863\n",
            "Epoch 10/50\n",
            "493/493 - 32s - loss: 0.0853 - val_loss: 0.0854\n",
            "Epoch 11/50\n",
            "493/493 - 32s - loss: 0.0850 - val_loss: 0.0852\n",
            "Epoch 12/50\n",
            "493/493 - 32s - loss: 0.0847 - val_loss: 0.0856\n",
            "Epoch 13/50\n",
            "493/493 - 32s - loss: 0.0846 - val_loss: 0.0856\n",
            "Epoch 14/50\n",
            "493/493 - 32s - loss: 0.0844 - val_loss: 0.0852\n",
            "Epoch 15/50\n",
            "493/493 - 32s - loss: 0.0842 - val_loss: 0.0843\n",
            "Epoch 16/50\n",
            "493/493 - 32s - loss: 0.0840 - val_loss: 0.0845\n",
            "Epoch 17/50\n",
            "493/493 - 32s - loss: 0.0839 - val_loss: 0.0844\n",
            "Epoch 18/50\n",
            "493/493 - 32s - loss: 0.0838 - val_loss: 0.0843\n",
            "Epoch 19/50\n",
            "493/493 - 32s - loss: 0.0836 - val_loss: 0.0841\n",
            "Epoch 20/50\n",
            "493/493 - 32s - loss: 0.0834 - val_loss: 0.0840\n",
            "Epoch 21/50\n",
            "493/493 - 32s - loss: 0.0833 - val_loss: 0.0846\n",
            "Epoch 22/50\n",
            "493/493 - 32s - loss: 0.0832 - val_loss: 0.0839\n",
            "Epoch 23/50\n",
            "493/493 - 32s - loss: 0.0831 - val_loss: 0.0841\n",
            "Epoch 24/50\n",
            "493/493 - 32s - loss: 0.0830 - val_loss: 0.0838\n",
            "Epoch 25/50\n",
            "493/493 - 32s - loss: 0.0829 - val_loss: 0.0841\n",
            "Epoch 26/50\n",
            "493/493 - 32s - loss: 0.0828 - val_loss: 0.0836\n",
            "Epoch 27/50\n",
            "493/493 - 32s - loss: 0.0827 - val_loss: 0.0850\n",
            "Epoch 28/50\n",
            "493/493 - 32s - loss: 0.0826 - val_loss: 0.0836\n",
            "Epoch 29/50\n",
            "493/493 - 32s - loss: 0.0826 - val_loss: 0.0836\n",
            "Epoch 30/50\n",
            "493/493 - 32s - loss: 0.0825 - val_loss: 0.0837\n",
            "Epoch 31/50\n",
            "493/493 - 32s - loss: 0.0824 - val_loss: 0.0837\n",
            "Epoch 32/50\n",
            "493/493 - 32s - loss: 0.0823 - val_loss: 0.0833\n",
            "Epoch 33/50\n",
            "493/493 - 32s - loss: 0.0823 - val_loss: 0.0835\n",
            "Epoch 34/50\n",
            "493/493 - 32s - loss: 0.0822 - val_loss: 0.0833\n",
            "Epoch 35/50\n",
            "493/493 - 32s - loss: 0.0821 - val_loss: 0.0832\n",
            "Epoch 36/50\n",
            "493/493 - 32s - loss: 0.0820 - val_loss: 0.0832\n",
            "Epoch 37/50\n",
            "493/493 - 32s - loss: 0.0820 - val_loss: 0.0832\n",
            "Epoch 38/50\n",
            "493/493 - 32s - loss: 0.0819 - val_loss: 0.0832\n",
            "Epoch 39/50\n",
            "493/493 - 32s - loss: 0.0819 - val_loss: 0.0831\n",
            "Epoch 40/50\n",
            "493/493 - 32s - loss: 0.0818 - val_loss: 0.0830\n",
            "Epoch 41/50\n",
            "493/493 - 32s - loss: 0.0817 - val_loss: 0.0830\n",
            "Epoch 42/50\n",
            "493/493 - 32s - loss: 0.0817 - val_loss: 0.0831\n",
            "Epoch 43/50\n",
            "493/493 - 32s - loss: 0.0816 - val_loss: 0.0830\n",
            "Epoch 44/50\n",
            "493/493 - 32s - loss: 0.0816 - val_loss: 0.0831\n",
            "Epoch 45/50\n",
            "493/493 - 32s - loss: 0.0815 - val_loss: 0.0832\n",
            "Epoch 46/50\n",
            "493/493 - 32s - loss: 0.0815 - val_loss: 0.0833\n",
            "Epoch 47/50\n",
            "493/493 - 32s - loss: 0.0814 - val_loss: 0.0832\n",
            "Epoch 48/50\n",
            "493/493 - 32s - loss: 0.0814 - val_loss: 0.0831\n",
            "Epoch 49/50\n",
            "493/493 - 32s - loss: 0.0813 - val_loss: 0.0831\n",
            "Epoch 50/50\n",
            "493/493 - 32s - loss: 0.0812 - val_loss: 0.0835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4d0418c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "viH5k-YQ9EoK",
        "outputId": "d594549b-46eb-413b-cad1-f8eff0745c2a"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Create an empty array of pixels.\n",
        "batch = 4\n",
        "pixels = np.zeros(shape = (batch, ) + (pixel_cnn.input_shape)[1:])\n",
        "batch, rows, cols, channels = pixels.shape \n",
        "\n",
        "# Iterate over the pixels because generation has to be done sequentially pixel by pixel.\n",
        "for row in tqdm(range(rows)):\n",
        "  for col in range(cols):\n",
        "    for channel in range(channels):\n",
        "      # Feed the whole array and retrieving the pixel value probabilities for the next\n",
        "      # pixel\n",
        "      probs = pixel_cnn.predict(pixels)[:, row, col, channel]\n",
        "      # Use the probabilities to pick pixel values and append the values to the image\n",
        "      # frame.\n",
        "      pixels[:, row, col, channel] = tf.math.ceil(probs - tf.random.uniform(probs.shape))\n",
        "\n",
        "\n",
        "def deprocess_image(x):\n",
        "  # Stack the single channeled black and white image to RGB values.\n",
        "  x = np.stack((x,x,x), 2)\n",
        "\n",
        "  x *= 255.0\n",
        "  # Convert to uint8 and clip to the valid range [0, 255]\n",
        "  x = np.clip(x, 0, 255).astype(\"uint8\")\n",
        "  return x\n",
        "\n",
        "# Iterate over the generated images and plot them with matplotlib.\n",
        "for i, pic in enumerate(pixels):\n",
        "  keras.preprocessing.image.save_img(\"generated_image_{}.png\".format(i), deprocess_image(np.squeeze(pic, -1)))\n",
        "\n",
        "\n",
        "display(Image(\"generated_image_0.png\"))\n",
        "display(Image(\"generated_image_1.png\"))\n",
        "display(Image(\"generated_image_2.png\"))\n",
        "display(Image(\"generated_image_3.png\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 28/28 [00:32<00:00,  1.15s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAnklEQVR4nO2VSw7AIAhEi/H+V6YLE9PoMEBx06Sz6gIfw0d7XV+VqqpqEdIs9EmoiFRwGFqvHUBTsgaAoW4Tnrid25bQoEEekC5/EkXEKqjD6Oc3NMj7A5y61U3iiNwT9PWEl2AgeGJ/yjwA9sFxmsWlofEbHF2p1JvAoHCxqtDXMqGvbTJoRT/0vNhk4cWPLANzCs9H/g6hHbQeQEs3nlxLJsZ/w2MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAk0lEQVR4nO2VwQrAIAxDdez/f9kdBCltjanrwMNyc+AzrbEr5deZaq3J5bWH6Jpxw1DFchWDSmKtNQfqEq33TSjWkdBRu2zItNlgvysJDTt1L119TMipPSbhol5FCqR9H8qfkfCicqCdCBJ2kyAw6KxrqvfAlNuHdflRYuHLJ3FdC6fMnA9Dlcj8o/LJn4fVJ0P6AbL9OS0vGZFzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAe0lEQVR4nO1Uyw7AMAiy+/9/ZodetsQHaptlSbk2IiJW5OAXGP4zAKVmBFVXQYja6dW1RueLrSgNkSANp06T8ozCeOrQWc5u8ZTa/hT71EXGIA0AljPd8VXer3O6ndRfVCX8yz6U1AmwSq08tsZPdTpQ4Nw1A2VRHbqJGwr6NgiP8B+DAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAiElEQVR4nO2SwQ6AIAxDO+L//3I9mBjDyjbEeKJH0j5YGbC1tfWdTJ6SHAZMR5agCc4MQHsXDogAjsBBUg7r5+hsfeYOVLq7zN7ZvGldutP6Myegi9LQxR6Gvy+5vhZZVGljUkonMX4cqzSTX+tZ6WOrv1+Zehr6FMm4hCp0asl+XP5AZpb2ewL2azAnnLqNTQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12VBML-RAfjI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}