{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face image generation with StyleGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXDA1D244kFanKGWHe6sNA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lee-Gunju/AI-paper-code-review-for-personal-project/blob/master/Face_image_generation_with_StyleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FQBgkdnLgb0",
        "outputId": "6dd38c28-f6be-40e6-b8b4-f568739913be"
      },
      "source": [
        "pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\r\u001b[K     |▌                               | 10kB 24.0MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 23.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 17.1MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 14.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 9.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "GJRvUcfUNnkR",
        "outputId": "c73c9461-bc77-49f6-edd8-a69e5e7cc10f"
      },
      "source": [
        "pip install tensorflow_datasets==4.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_datasets==4.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/91/c3e36695ca04e6f3c2d920887d7dc36550f6bbb03d7d5fd03c2172b06d97/tensorflow_datasets-4.2.0-py3-none-any.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (5.2.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (1.1.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (2.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (21.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (1.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (0.3.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (2.23.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (0.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0) (4.41.1)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets==4.2.0) (3.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets==4.2.0) (1.53.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.2.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.2.0) (2021.5.30)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Found existing installation: tensorflow-datasets 4.0.1\n",
            "    Uninstalling tensorflow-datasets-4.0.1:\n",
            "      Successfully uninstalled tensorflow-datasets-4.0.1\n",
            "Successfully installed tensorflow-datasets-4.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow_datasets"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "MvLhFISoPEnn",
        "outputId": "f1bf4aeb-712a-4080-9fcf-c0ca3bb8749c"
      },
      "source": [
        "pip install tfds-nightly==4.2.0.dev202101190107"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tfds-nightly==4.2.0.dev202101190107\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/77/52e4d24540f2410934f55a2f979a88b97dacbbef9234cdac06ef6f89c8ab/tfds_nightly-4.2.0.dev202101190107-py3-none-any.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (0.3.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (3.17.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (4.41.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (0.12.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (2.23.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (1.1.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (5.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly==4.2.0.dev202101190107) (21.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly==4.2.0.dev202101190107) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly==4.2.0.dev202101190107) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly==4.2.0.dev202101190107) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly==4.2.0.dev202101190107) (1.24.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tfds-nightly==4.2.0.dev202101190107) (1.53.0)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tfds-nightly==4.2.0.dev202101190107) (3.4.1)\n",
            "Installing collected packages: tfds-nightly\n",
            "  Found existing installation: tfds-nightly 4.3.0.dev202107080107\n",
            "    Uninstalling tfds-nightly-4.3.0.dev202107080107:\n",
            "      Successfully uninstalled tfds-nightly-4.3.0.dev202107080107\n",
            "Successfully installed tfds-nightly-4.2.0.dev202101190107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow_datasets"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NahtTlHrNMOF",
        "outputId": "6604c729-6234-4faa-de51-d28e8ecc66e9"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "print(tfds.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.2.0+nightly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8k6ReJiJxQf"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from enum import Enum\n",
        "from glob import glob\n",
        "from functools import partial\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVdcorRGKPoV"
      },
      "source": [
        "def log2(x):\n",
        "    return int(np.log2(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydSbnuaeLkuT"
      },
      "source": [
        "# we use different batch size for different resolution, so larger image size\n",
        "# could fit into GPU memory. The keys is image resolution in log2\n",
        "batch_sizes = {2: 16, 3: 16, 4: 16, 5: 16, 6: 16, 7: 8, 8: 4, 9: 2, 10: 1}\n",
        "# We adjust the train step accordingly\n",
        "train_step_ratio = {k: batch_sizes[2] / v for k, v in batch_sizes.items()}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZogRkq-2LxSz",
        "outputId": "a6d76de5-25cf-4495-ba89-8bff13af3240"
      },
      "source": [
        "train_step_ratio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 2.0, 8: 4.0, 9: 8.0, 10: 16.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWZBzyZtLxtb"
      },
      "source": [
        "ds_train = tfds.load(\"celeb_a\", split=\"train\")\n",
        "\n",
        "\n",
        "def resize_image(res, sample):\n",
        "    image = sample[\"image\"]\n",
        "    # only donwsampling, so use nearest neighbor that is faster to run\n",
        "    image = tf.image.resize(\n",
        "        image, (res, res), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
        "    )\n",
        "    image = tf.cast(image, tf.float32) / 127.5 - 1.0\n",
        "    return image\n",
        "\n",
        "def create_dataloader(res):\n",
        "    batch_size = batch_sizes[log2(res)]\n",
        "    dl = ds_train.map(partial(resize_image, res), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dl = dl.shuffle(200).batch(batch_size, drop_remainder=True).prefetch(1).repeat()\n",
        "    return dl\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDC7EmJ-MdMs"
      },
      "source": [
        "ds_train = tfds.load(\"celeb_a\", split=\"train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7tkZGmvMgmk"
      },
      "source": [
        "tfds.list_builders()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S3x0czHQfvc"
      },
      "source": [
        "def plot_images(images, log2_res, fname=\"\"):\n",
        "    scales = {2: 0.5, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8}\n",
        "    scale = scales[log2_res]\n",
        "\n",
        "    grid_col = min(images.shape[0], int(32 // scale))\n",
        "    grid_row = 1\n",
        "\n",
        "    f, axarr = plt.subplots(\n",
        "        grid_row, grid_col, figsize=(grid_col * scale, grid_row * scale)\n",
        "    )\n",
        "\n",
        "    for row in range(grid_row):\n",
        "        ax = axarr if grid_row == 1 else axarr[row]\n",
        "        for col in range(grid_col):\n",
        "            ax[col].imshow(images[row * grid_col + col])\n",
        "            ax[col].axis(\"off\")\n",
        "    plt.show()\n",
        "    if fname:\n",
        "        f.savefig(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbj_bZmQRVus"
      },
      "source": [
        "def fade_in(alpha, a, b):\n",
        "    return alpha * a + (1.0 - alpha) * b\n",
        "\n",
        "\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return -tf.reduce_mean(y_true * y_pred)\n",
        "\n",
        "\n",
        "def pixel_norm(x, epsilon=1e-8):\n",
        "    return x / tf.math.sqrt(tf.reduce_mean(x ** 2, axis=-1, keepdims=True) + epsilon)\n",
        "\n",
        "\n",
        "def minibatch_std(input_tensor, epsilon=1e-8):\n",
        "    n, h, w, c = tf.shape(input_tensor)\n",
        "    group_size = tf.minimum(4, n)\n",
        "    x = tf.reshape(input_tensor, [group_size, -1, h, w, c])\n",
        "    group_mean, group_var = tf.nn.moments(x, axes=(0), keepdims=False)\n",
        "    group_std = tf.sqrt(group_var + epsilon)\n",
        "    avg_std = tf.reduce_mean(group_std, axis=[1, 2, 3], keepdims=True)\n",
        "    x = tf.tile(avg_std, [group_size, h, w, 1])\n",
        "    return tf.concat([input_tensor, x], axis=-1)\n",
        "\n",
        "\n",
        "class EqualizedConv(layers.Layer):\n",
        "    def __init__(self, out_channels, kernel=3, gain=2, **kwargs):\n",
        "        super(EqualizedConv, self).__init__(**kwargs)\n",
        "        self.kernel = kernel\n",
        "        self.out_channels = out_channels\n",
        "        self.gain = gain\n",
        "        self.pad = kernel != 1\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.in_channels = input_shape[-1]\n",
        "        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n",
        "        self.w = self.add_weight(\n",
        "            shape=[self.kernel, self.kernel, self.in_channels, self.out_channels],\n",
        "            initializer=initializer,\n",
        "            trainable=True,\n",
        "            name=\"kernel\",\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.out_channels,), initializer=\"zeros\", trainable=True, name=\"bias\"\n",
        "        )\n",
        "        fan_in = self.kernel * self.kernel * self.in_channels\n",
        "        self.scale = tf.sqrt(self.gain / fan_in)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.pad:\n",
        "            x = tf.pad(inputs, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\"REFLECT\")\n",
        "        else:\n",
        "            x = inputs\n",
        "        output = (\n",
        "            tf.nn.conv2d(x, self.scale * self.w, strides=1, padding=\"VALID\") + self.b\n",
        "        )\n",
        "        return output\n",
        "\n",
        "\n",
        "class EqualizedDense(layers.Layer):\n",
        "    def __init__(self, units, gain=2, learning_rate_multiplier=1, **kwargs):\n",
        "        super(EqualizedDense, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.gain = gain\n",
        "        self.learning_rate_multiplier = learning_rate_multiplier\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.in_channels = input_shape[-1]\n",
        "        initializer = keras.initializers.RandomNormal(\n",
        "            mean=0.0, stddev=1.0 / self.learning_rate_multiplier\n",
        "        )\n",
        "        self.w = self.add_weight(\n",
        "            shape=[self.in_channels, self.units],\n",
        "            initializer=initializer,\n",
        "            trainable=True,\n",
        "            name=\"kernel\",\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,), initializer=\"zeros\", trainable=True, name=\"bias\"\n",
        "        )\n",
        "        fan_in = self.in_channels\n",
        "        self.scale = tf.sqrt(self.gain / fan_in)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = tf.add(tf.matmul(inputs, self.scale * self.w), self.b)\n",
        "        return output * self.learning_rate_multiplier\n",
        "\n",
        "\n",
        "class AddNoise(layers.Layer):\n",
        "    def build(self, input_shape):\n",
        "        n, h, w, c = input_shape[0]\n",
        "        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n",
        "        self.b = self.add_weight(\n",
        "            shape=[1, 1, 1, c], initializer=initializer, trainable=True, name=\"kernel\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, noise = inputs\n",
        "        output = x + self.b * noise\n",
        "        return output\n",
        "\n",
        "\n",
        "class AdaIN(layers.Layer):\n",
        "    def __init__(self, gain=1, **kwargs):\n",
        "        super(AdaIN, self).__init__(**kwargs)\n",
        "        self.gain = gain\n",
        "\n",
        "    def build(self, input_shapes):\n",
        "        x_shape = input_shapes[0]\n",
        "        w_shape = input_shapes[1]\n",
        "\n",
        "        self.w_channels = w_shape[-1]\n",
        "        self.x_channels = x_shape[-1]\n",
        "\n",
        "        self.dense_1 = EqualizedDense(self.x_channels, gain=1)\n",
        "        self.dense_2 = EqualizedDense(self.x_channels, gain=1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, w = inputs\n",
        "        ys = tf.reshape(self.dense_1(w), (-1, 1, 1, self.x_channels))\n",
        "        yb = tf.reshape(self.dense_2(w), (-1, 1, 1, self.x_channels))\n",
        "        return ys * x + yb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1s41bNHSKyV"
      },
      "source": [
        "def Mapping(num_stages, input_shape=512):\n",
        "    z = layers.Input(shape=(input_shape))\n",
        "    w = pixel_norm(z)\n",
        "    for i in range(8):\n",
        "        w = EqualizedDense(512, learning_rate_multiplier=0.01)(w)\n",
        "        w = layers.LeakyReLU(0.2)(w)\n",
        "    w = tf.tile(tf.expand_dims(w, 1), (1, num_stages, 1))\n",
        "    return keras.Model(z, w, name=\"mapping\")\n",
        "\n",
        "\n",
        "class Generator:\n",
        "    def __init__(self, start_res_log2, target_res_log2):\n",
        "        self.start_res_log2 = start_res_log2\n",
        "        self.target_res_log2 = target_res_log2\n",
        "        self.num_stages = target_res_log2 - start_res_log2 + 1\n",
        "        # list of generator blocks at increasing resolution\n",
        "        self.g_blocks = []\n",
        "        # list of layers to convert g_block activation to RGB\n",
        "        self.to_rgb = []\n",
        "        # list of noise input of different resolutions into g_blocks\n",
        "        self.noise_inputs = []\n",
        "        # filter size to use at each stage, keys are log2(resolution)\n",
        "        self.filter_nums = {\n",
        "            0: 512,\n",
        "            1: 512,\n",
        "            2: 512,  # 4x4\n",
        "            3: 512,  # 8x8\n",
        "            4: 512,  # 16x16\n",
        "            5: 512,  # 32x32\n",
        "            6: 256,  # 64x64\n",
        "            7: 128,  # 128x128\n",
        "            8: 64,  # 256x256\n",
        "            9: 32,  # 512x512\n",
        "            10: 16,\n",
        "        }  # 1024x1024\n",
        "\n",
        "        start_res = 2 ** start_res_log2\n",
        "        self.input_shape = (start_res, start_res, self.filter_nums[start_res_log2])\n",
        "        self.g_input = layers.Input(self.input_shape, name=\"generator_input\")\n",
        "\n",
        "        for i in range(start_res_log2, target_res_log2 + 1):\n",
        "            filter_num = self.filter_nums[i]\n",
        "            res = 2 ** i\n",
        "            self.noise_inputs.append(\n",
        "                layers.Input(shape=(res, res, 1), name=f\"noise_{res}x{res}\")\n",
        "            )\n",
        "            to_rgb = Sequential(\n",
        "                [\n",
        "                    layers.InputLayer(input_shape=(res, res, filter_num)),\n",
        "                    EqualizedConv(3, 1, gain=1),\n",
        "                ],\n",
        "                name=f\"to_rgb_{res}x{res}\",\n",
        "            )\n",
        "            self.to_rgb.append(to_rgb)\n",
        "            is_base = i == self.start_res_log2\n",
        "            if is_base:\n",
        "                input_shape = (res, res, self.filter_nums[i - 1])\n",
        "            else:\n",
        "                input_shape = (2 ** (i - 1), 2 ** (i - 1), self.filter_nums[i - 1])\n",
        "            g_block = self.build_block(\n",
        "                filter_num, res=res, input_shape=input_shape, is_base=is_base\n",
        "            )\n",
        "            self.g_blocks.append(g_block)\n",
        "\n",
        "    def build_block(self, filter_num, res, input_shape, is_base):\n",
        "        input_tensor = layers.Input(shape=input_shape, name=f\"g_{res}\")\n",
        "        noise = layers.Input(shape=(res, res, 1), name=f\"noise_{res}\")\n",
        "        w = layers.Input(shape=512)\n",
        "        x = input_tensor\n",
        "\n",
        "        if not is_base:\n",
        "            x = layers.UpSampling2D((2, 2))(x)\n",
        "            x = EqualizedConv(filter_num, 3)(x)\n",
        "\n",
        "        x = AddNoise()([x, noise])\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = InstanceNormalization()(x)\n",
        "        x = AdaIN()([x, w])\n",
        "\n",
        "        x = EqualizedConv(filter_num, 3)(x)\n",
        "        x = AddNoise()([x, noise])\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = InstanceNormalization()(x)\n",
        "        x = AdaIN()([x, w])\n",
        "        return keras.Model([input_tensor, w, noise], x, name=f\"genblock_{res}x{res}\")\n",
        "\n",
        "    def grow(self, res_log2):\n",
        "        res = 2 ** res_log2\n",
        "\n",
        "        num_stages = res_log2 - self.start_res_log2 + 1\n",
        "        w = layers.Input(shape=(self.num_stages, 512), name=\"w\")\n",
        "\n",
        "        alpha = layers.Input(shape=(1), name=\"g_alpha\")\n",
        "        x = self.g_blocks[0]([self.g_input, w[:, 0], self.noise_inputs[0]])\n",
        "\n",
        "        if num_stages == 1:\n",
        "            rgb = self.to_rgb[0](x)\n",
        "        else:\n",
        "            for i in range(1, num_stages - 1):\n",
        "\n",
        "                x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n",
        "\n",
        "            old_rgb = self.to_rgb[num_stages - 2](x)\n",
        "            old_rgb = layers.UpSampling2D((2, 2))(old_rgb)\n",
        "\n",
        "            i = num_stages - 1\n",
        "            x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n",
        "\n",
        "            new_rgb = self.to_rgb[i](x)\n",
        "\n",
        "            rgb = fade_in(alpha[0], new_rgb, old_rgb)\n",
        "\n",
        "        return keras.Model(\n",
        "            [self.g_input, w, self.noise_inputs, alpha],\n",
        "            rgb,\n",
        "            name=f\"generator_{res}_x_{res}\",\n",
        "        )\n",
        "\n",
        "\n",
        "class Discriminator:\n",
        "    def __init__(self, start_res_log2, target_res_log2):\n",
        "        self.start_res_log2 = start_res_log2\n",
        "        self.target_res_log2 = target_res_log2\n",
        "        self.num_stages = target_res_log2 - start_res_log2 + 1\n",
        "        # filter size to use at each stage, keys are log2(resolution)\n",
        "        self.filter_nums = {\n",
        "            0: 512,\n",
        "            1: 512,\n",
        "            2: 512,  # 4x4\n",
        "            3: 512,  # 8x8\n",
        "            4: 512,  # 16x16\n",
        "            5: 512,  # 32x32\n",
        "            6: 256,  # 64x64\n",
        "            7: 128,  # 128x128\n",
        "            8: 64,  # 256x256\n",
        "            9: 32,  # 512x512\n",
        "            10: 16,\n",
        "        }  # 1024x1024\n",
        "        # list of discriminator blocks at increasing resolution\n",
        "        self.d_blocks = []\n",
        "        # list of layers to convert RGB into activation for d_blocks inputs\n",
        "        self.from_rgb = []\n",
        "\n",
        "        for res_log2 in range(self.start_res_log2, self.target_res_log2 + 1):\n",
        "            res = 2 ** res_log2\n",
        "            filter_num = self.filter_nums[res_log2]\n",
        "            from_rgb = Sequential(\n",
        "                [\n",
        "                    layers.InputLayer(\n",
        "                        input_shape=(res, res, 3), name=f\"from_rgb_input_{res}\"\n",
        "                    ),\n",
        "                    EqualizedConv(filter_num, 1),\n",
        "                    layers.LeakyReLU(0.2),\n",
        "                ],\n",
        "                name=f\"from_rgb_{res}\",\n",
        "            )\n",
        "\n",
        "            self.from_rgb.append(from_rgb)\n",
        "\n",
        "            input_shape = (res, res, filter_num)\n",
        "            if len(self.d_blocks) == 0:\n",
        "                d_block = self.build_base(filter_num, res)\n",
        "            else:\n",
        "                d_block = self.build_block(\n",
        "                    filter_num, self.filter_nums[res_log2 - 1], res\n",
        "                )\n",
        "\n",
        "            self.d_blocks.append(d_block)\n",
        "\n",
        "    def build_base(self, filter_num, res):\n",
        "        input_tensor = layers.Input(shape=(res, res, filter_num), name=f\"d_{res}\")\n",
        "        x = minibatch_std(input_tensor)\n",
        "        x = EqualizedConv(filter_num, 3)(x)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = layers.Flatten()(x)\n",
        "        x = EqualizedDense(filter_num)(x)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = EqualizedDense(1)(x)\n",
        "        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n",
        "\n",
        "    def build_block(self, filter_num_1, filter_num_2, res):\n",
        "        input_tensor = layers.Input(shape=(res, res, filter_num_1), name=f\"d_{res}\")\n",
        "        x = EqualizedConv(filter_num_1, 3)(input_tensor)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = EqualizedConv(filter_num_2)(x)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = layers.AveragePooling2D((2, 2))(x)\n",
        "        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n",
        "\n",
        "    def grow(self, res_log2):\n",
        "        res = 2 ** res_log2\n",
        "        idx = res_log2 - self.start_res_log2\n",
        "        alpha = layers.Input(shape=(1), name=\"d_alpha\")\n",
        "        input_image = layers.Input(shape=(res, res, 3), name=\"input_image\")\n",
        "        x = self.from_rgb[idx](input_image)\n",
        "        x = self.d_blocks[idx](x)\n",
        "        if idx > 0:\n",
        "            idx -= 1\n",
        "            downsized_image = layers.AveragePooling2D((2, 2))(input_image)\n",
        "            y = self.from_rgb[idx](downsized_image)\n",
        "            x = fade_in(alpha[0], x, y)\n",
        "\n",
        "            for i in range(idx, -1, -1):\n",
        "                x = self.d_blocks[i](x)\n",
        "        return keras.Model([input_image, alpha], x, name=f\"discriminator_{res}_x_{res}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQNF0ZqTTFXt"
      },
      "source": [
        "class StyleGAN(tf.keras.Model):\n",
        "    def __init__(self, z_dim=512, target_res=64, start_res=4):\n",
        "        super(StyleGAN, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.target_res_log2 = log2(target_res)\n",
        "        self.start_res_log2 = log2(start_res)\n",
        "        self.current_res_log2 = self.target_res_log2\n",
        "        self.num_stages = self.target_res_log2 - self.start_res_log2 + 1\n",
        "\n",
        "        self.alpha = tf.Variable(1.0, dtype=tf.float32, trainable=False, name=\"alpha\")\n",
        "\n",
        "        self.mapping = Mapping(num_stages=self.num_stages)\n",
        "        self.d_builder = Discriminator(self.start_res_log2, self.target_res_log2)\n",
        "        self.g_builder = Generator(self.start_res_log2, self.target_res_log2)\n",
        "        self.g_input_shape = self.g_builder.input_shape\n",
        "\n",
        "        self.phase = None\n",
        "        self.train_step_counter = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
        "\n",
        "        self.loss_weights = {\"gradient_penalty\": 10, \"drift\": 0.001}\n",
        "\n",
        "    def grow_model(self, res):\n",
        "        tf.keras.backend.clear_session()\n",
        "        res_log2 = log2(res)\n",
        "        self.generator = self.g_builder.grow(res_log2)\n",
        "        self.discriminator = self.d_builder.grow(res_log2)\n",
        "        self.current_res_log2 = res_log2\n",
        "        print(f\"\\nModel resolution:{res}x{res}\")\n",
        "\n",
        "    def compile(\n",
        "        self, steps_per_epoch, phase, res, d_optimizer, g_optimizer, *args, **kwargs\n",
        "    ):\n",
        "        self.loss_weights = kwargs.pop(\"loss_weights\", self.loss_weights)\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        if res != 2 ** self.current_res_log2:\n",
        "            self.grow_model(res)\n",
        "            self.d_optimizer = d_optimizer\n",
        "            self.g_optimizer = g_optimizer\n",
        "\n",
        "        self.train_step_counter.assign(0)\n",
        "        self.phase = phase\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "        super(StyleGAN, self).compile(*args, **kwargs)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def generate_noise(self, batch_size):\n",
        "        noise = [\n",
        "            tf.random.normal((batch_size, 2 ** res, 2 ** res, 1))\n",
        "            for res in range(self.start_res_log2, self.target_res_log2 + 1)\n",
        "        ]\n",
        "        return noise\n",
        "\n",
        "    def gradient_loss(self, grad):\n",
        "        loss = tf.square(grad)\n",
        "        loss = tf.reduce_sum(loss, axis=tf.range(1, tf.size(tf.shape(loss))))\n",
        "        loss = tf.sqrt(loss)\n",
        "        loss = tf.reduce_mean(tf.square(loss - 1))\n",
        "        return loss\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "\n",
        "        self.train_step_counter.assign_add(1)\n",
        "\n",
        "        if self.phase == \"TRANSITION\":\n",
        "            self.alpha.assign(\n",
        "                tf.cast(self.train_step_counter / self.steps_per_epoch, tf.float32)\n",
        "            )\n",
        "        elif self.phase == \"STABLE\":\n",
        "            self.alpha.assign(1.0)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        alpha = tf.expand_dims(self.alpha, 0)\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        real_labels = tf.ones(batch_size)\n",
        "        fake_labels = -tf.ones(batch_size)\n",
        "\n",
        "        z = tf.random.normal((batch_size, self.z_dim))\n",
        "        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n",
        "        noise = self.generate_noise(batch_size)\n",
        "\n",
        "        # generator\n",
        "        with tf.GradientTape() as g_tape:\n",
        "            w = self.mapping(z)\n",
        "            fake_images = self.generator([const_input, w, noise, alpha])\n",
        "            pred_fake = self.discriminator([fake_images, alpha])\n",
        "            g_loss = wasserstein_loss(real_labels, pred_fake)\n",
        "\n",
        "            trainable_weights = (\n",
        "                self.mapping.trainable_weights + self.generator.trainable_weights\n",
        "            )\n",
        "            gradients = g_tape.gradient(g_loss, trainable_weights)\n",
        "            self.g_optimizer.apply_gradients(zip(gradients, trainable_weights))\n",
        "\n",
        "        # discriminator\n",
        "        with tf.GradientTape() as gradient_tape, tf.GradientTape() as total_tape:\n",
        "            # forward pass\n",
        "            pred_fake = self.discriminator([fake_images, alpha])\n",
        "            pred_real = self.discriminator([real_images, alpha])\n",
        "\n",
        "            epsilon = tf.random.uniform((batch_size, 1, 1, 1))\n",
        "            interpolates = epsilon * real_images + (1 - epsilon) * fake_images\n",
        "            gradient_tape.watch(interpolates)\n",
        "            pred_fake_grad = self.discriminator([interpolates, alpha])\n",
        "\n",
        "            # calculate losses\n",
        "            loss_fake = wasserstein_loss(fake_labels, pred_fake)\n",
        "            loss_real = wasserstein_loss(real_labels, pred_real)\n",
        "            loss_fake_grad = wasserstein_loss(fake_labels, pred_fake_grad)\n",
        "\n",
        "            # gradient penalty\n",
        "            gradients_fake = gradient_tape.gradient(loss_fake_grad, [interpolates])\n",
        "            gradient_penalty = self.loss_weights[\n",
        "                \"gradient_penalty\"\n",
        "            ] * self.gradient_loss(gradients_fake)\n",
        "\n",
        "            # drift loss\n",
        "            all_pred = tf.concat([pred_fake, pred_real], axis=0)\n",
        "            drift_loss = self.loss_weights[\"drift\"] * tf.reduce_mean(all_pred ** 2)\n",
        "\n",
        "            d_loss = loss_fake + loss_real + gradient_penalty + drift_loss\n",
        "\n",
        "            gradients = total_tape.gradient(\n",
        "                d_loss, self.discriminator.trainable_weights\n",
        "            )\n",
        "            self.d_optimizer.apply_gradients(\n",
        "                zip(gradients, self.discriminator.trainable_weights)\n",
        "            )\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n",
        "\n",
        "    def call(self, inputs: dict()):\n",
        "        style_code = inputs.get(\"style_code\", None)\n",
        "        z = inputs.get(\"z\", None)\n",
        "        noise = inputs.get(\"noise\", None)\n",
        "        batch_size = inputs.get(\"batch_size\", 1)\n",
        "        alpha = inputs.get(\"alpha\", 1.0)\n",
        "        alpha = tf.expand_dims(alpha, 0)\n",
        "        if style_code is None:\n",
        "            if z is None:\n",
        "                z = tf.random.normal((batch_size, self.z_dim))\n",
        "            style_code = self.mapping(z)\n",
        "\n",
        "        if noise is None:\n",
        "            noise = self.generate_noise(batch_size)\n",
        "\n",
        "        # self.alpha.assign(alpha)\n",
        "\n",
        "        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n",
        "        images = self.generator([const_input, style_code, noise, alpha])\n",
        "        images = np.clip((images * 0.5 + 0.5) * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "        return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObbEi__pT7um"
      },
      "source": [
        "START_RES = 4\n",
        "TARGET_RES = 128\n",
        "\n",
        "style_gan = StyleGAN(start_res=START_RES, target_res=TARGET_RES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "PVfxUPiKUb0Q",
        "outputId": "70947132-9912-4d4a-d83c-78b32138a132"
      },
      "source": [
        "keras.utils.plot_model(style_gan)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OWlF_V4T9a2"
      },
      "source": [
        "def train(\n",
        "    start_res=START_RES,\n",
        "    target_res=TARGET_RES,\n",
        "    steps_per_epoch=5000,\n",
        "    display_images=True,\n",
        "):\n",
        "    opt_cfg = {\"learning_rate\": 1e-3, \"beta_1\": 0.0, \"beta_2\": 0.99, \"epsilon\": 1e-8}\n",
        "\n",
        "    val_batch_size = 16\n",
        "    val_z = tf.random.normal((val_batch_size, style_gan.z_dim))\n",
        "    val_noise = style_gan.generate_noise(val_batch_size)\n",
        "\n",
        "    start_res_log2 = int(np.log2(start_res))\n",
        "    target_res_log2 = int(np.log2(target_res))\n",
        "\n",
        "    for res_log2 in range(start_res_log2, target_res_log2 + 1):\n",
        "        res = 2 ** res_log2\n",
        "        for phase in [\"TRANSITION\", \"STABLE\"]:\n",
        "            if res == start_res and phase == \"TRANSITION\":\n",
        "                continue\n",
        "\n",
        "            train_dl = create_dataloader(res)\n",
        "\n",
        "            steps = int(train_step_ratio[res_log2] * steps_per_epoch)\n",
        "\n",
        "            style_gan.compile(\n",
        "                d_optimizer=tf.keras.optimizers.Adam(**opt_cfg),\n",
        "                g_optimizer=tf.keras.optimizers.Adam(**opt_cfg),\n",
        "                loss_weights={\"gradient_penalty\": 10, \"drift\": 0.001},\n",
        "                steps_per_epoch=steps,\n",
        "                res=res,\n",
        "                phase=phase,\n",
        "                run_eagerly=False,\n",
        "            )\n",
        "\n",
        "            prefix = f\"res_{res}x{res}_{style_gan.phase}\"\n",
        "\n",
        "            ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
        "                f\"checkpoints/stylegan_{res}x{res}.ckpt\",\n",
        "                save_weights_only=True,\n",
        "                verbose=0,\n",
        "            )\n",
        "            print(phase)\n",
        "            style_gan.fit(\n",
        "                train_dl, epochs=1, steps_per_epoch=steps, callbacks=[ckpt_cb]\n",
        "            )\n",
        "\n",
        "            if display_images:\n",
        "                images = style_gan({\"z\": val_z, \"noise\": val_noise, \"alpha\": 1.0})\n",
        "                plot_images(images, res_log2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_i15iMwUic_"
      },
      "source": [
        "train(start_res=4, target_res=16, steps_per_epoch=1, display_images=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK6KrJ2FUmMa"
      },
      "source": [
        "url = \"https://github.com/soon-yau/stylegan_keras/releases/download/keras_example_v1.0/stylegan_128x128.ckpt.zip\"\n",
        "\n",
        "weights_path = keras.utils.get_file(\n",
        "    \"stylegan_128x128.ckpt.zip\",\n",
        "    url,\n",
        "    extract=True,\n",
        "    cache_dir=os.path.abspath(\".\"),\n",
        "    cache_subdir=\"pretrained\",\n",
        ")\n",
        "\n",
        "style_gan.grow_model(128)\n",
        "style_gan.load_weights(os.path.join(\"pretrained/stylegan_128x128.ckpt\"))\n",
        "\n",
        "tf.random.set_seed(196)\n",
        "batch_size = 2\n",
        "z = tf.random.normal((batch_size, style_gan.z_dim))\n",
        "w = style_gan.mapping(z)\n",
        "noise = style_gan.generate_noise(batch_size=batch_size)\n",
        "images = style_gan({\"style_code\": w, \"noise\": noise, \"alpha\": 1.0})\n",
        "plot_images(images, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbNA8oVXUmpq"
      },
      "source": [
        "alpha = 0.4\n",
        "w_mix = np.expand_dims(alpha * w[0] + (1 - alpha) * w[1], 0)\n",
        "noise_a = [np.expand_dims(n[0], 0) for n in noise]\n",
        "mix_images = style_gan({\"style_code\": w_mix, \"noise\": noise_a})\n",
        "image_row = np.hstack([images[0], images[1], mix_images[0]])\n",
        "plt.figure(figsize=(9, 3))\n",
        "plt.imshow(image_row)\n",
        "plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}