{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Supervised Contrastive Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/xNg1x8G5AhmwIpGmNUHZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lee-Gunju/AI-paper-code-review-for-personal-project/blob/master/Supervised_Contrastive_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMQdcKJP0hhe",
        "outputId": "2d907bac-f81e-47d3-9ead-4bf71e50decc"
      },
      "source": [
        "pip install tensorflow-addons\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\r\u001b[K     |▌                               | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 25.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 24.0MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 17.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 8.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 10.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 10.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XNPUJIK9lD-"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJJOcymH9lyl",
        "outputId": "ea9d9db4-1c86-4593-fa6e-dd40c729266f"
      },
      "source": [
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Load the train and test data splits\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Display shapes of train and test datasets\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA8TZ_4j9m0l"
      },
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "                                      layers.experimental.preprocessing.Normalization(),\n",
        "                                      layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "                                      layers.experimental.preprocessing.RandomRotation(0.02),\n",
        "                                      layers.experimental.preprocessing.RandomWidth(0.2),\n",
        "                                      layers.experimental.preprocessing.RandomHeight(0.2)\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzK3dxS6-HgK",
        "outputId": "81141d2d-82f2-4222-8920-b37e4d83ff7f"
      },
      "source": [
        "def create_encoder():\n",
        "  resnet = keras.applications.ResNet50V2(\n",
        "      include_top = False, weights = None, input_shape = input_shape, pooling='avg'\n",
        "  )\n",
        "  inputs = keras.Input(shape = input_shape)\n",
        "  augmented = data_augmentation(inputs)\n",
        "  outputs = resnet(augmented)\n",
        "  model = keras.Model(inputs = inputs, outputs = outputs, name = 'cifar10-encoder')\n",
        "  return model \n",
        "\n",
        "encoder = create_encoder()\n",
        "encoder.summary()\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 265\n",
        "hidden_units = 512\n",
        "projection_units = 128\n",
        "num_epochs = 50\n",
        "dropout_rate = 0.5\n",
        "temperature = 0.05"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cifar10-encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, None, None, 3)     7         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, 2048)              23564800  \n",
            "=================================================================\n",
            "Total params: 23,564,807\n",
            "Trainable params: 23,519,360\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSZK932Q-vhv"
      },
      "source": [
        "def create_classifier(encoder, trainable=True):\n",
        "  for layer in encoder.layers:\n",
        "    layer.trainable = trainable \n",
        "\n",
        "  inputs = keras.Input(shape =input_shape)\n",
        "  features = encoder(inputs)\n",
        "  features = layers.Dropout(dropout_rate)(features)\n",
        "  features = layers.Dense(hidden_units, activation='relu')(features)\n",
        "  features = layers.Dropout(dropout_rate)(features)\n",
        "  outputs = layers.Dense(num_classes, activation='softmax')(features)\n",
        "\n",
        "  model = keras.Model(inputs = inputs, outputs = outputs, name = 'cifar10-classifier')\n",
        "  model.compile(optimizer = keras.optimizers.Adam(learning_rate),\n",
        "                loss = keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics = [keras.metrics.SparseCategoricalAccuracy()])\n",
        "  \n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F4RrlDShAzv1",
        "outputId": "e7534520-902f-4bc9-e75e-92d22575e00b"
      },
      "source": [
        "endoer = create_encoder()\n",
        "classifier = create_classifier(encoder)\n",
        "classifier.summary()\n",
        "\n",
        "history = classifier.fit(x =x_train, y=y_train, batch_size= batch_size, epochs = num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cifar10-classifier\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "cifar10-encoder (Functional) (None, 2048)              23564807  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 24,619,025\n",
            "Trainable params: 24,573,578\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "189/189 [==============================] - 99s 307ms/step - loss: 1.9601 - sparse_categorical_accuracy: 0.2759\n",
            "Epoch 2/50\n",
            "189/189 [==============================] - 29s 152ms/step - loss: 1.5257 - sparse_categorical_accuracy: 0.4434\n",
            "Epoch 3/50\n",
            "189/189 [==============================] - 27s 141ms/step - loss: 1.3506 - sparse_categorical_accuracy: 0.5175\n",
            "Epoch 4/50\n",
            "189/189 [==============================] - 29s 156ms/step - loss: 1.2586 - sparse_categorical_accuracy: 0.5571\n",
            "Epoch 5/50\n",
            "189/189 [==============================] - 30s 157ms/step - loss: 1.1257 - sparse_categorical_accuracy: 0.6067\n",
            "Epoch 6/50\n",
            "189/189 [==============================] - 25s 131ms/step - loss: 1.0567 - sparse_categorical_accuracy: 0.6314\n",
            "Epoch 7/50\n",
            "189/189 [==============================] - 29s 153ms/step - loss: 0.9805 - sparse_categorical_accuracy: 0.6617\n",
            "Epoch 8/50\n",
            "189/189 [==============================] - 25s 132ms/step - loss: 0.9143 - sparse_categorical_accuracy: 0.6851\n",
            "Epoch 9/50\n",
            "189/189 [==============================] - 25s 131ms/step - loss: 0.8784 - sparse_categorical_accuracy: 0.6987\n",
            "Epoch 10/50\n",
            "189/189 [==============================] - 25s 134ms/step - loss: 1.1180 - sparse_categorical_accuracy: 0.6096\n",
            "Epoch 11/50\n",
            "189/189 [==============================] - 25s 133ms/step - loss: 0.9213 - sparse_categorical_accuracy: 0.6846\n",
            "Epoch 12/50\n",
            "189/189 [==============================] - 25s 133ms/step - loss: 0.8610 - sparse_categorical_accuracy: 0.7070\n",
            "Epoch 13/50\n",
            "189/189 [==============================] - 25s 133ms/step - loss: 0.8114 - sparse_categorical_accuracy: 0.7225\n",
            "Epoch 14/50\n",
            "189/189 [==============================] - 25s 133ms/step - loss: 0.7873 - sparse_categorical_accuracy: 0.7327\n",
            "Epoch 15/50\n",
            "189/189 [==============================] - 25s 133ms/step - loss: 0.7166 - sparse_categorical_accuracy: 0.7555\n",
            "Epoch 16/50\n",
            "189/189 [==============================] - 26s 135ms/step - loss: 0.7042 - sparse_categorical_accuracy: 0.7589\n",
            "Epoch 17/50\n",
            "189/189 [==============================] - 25s 133ms/step - loss: 0.6550 - sparse_categorical_accuracy: 0.7765\n",
            "Epoch 18/50\n",
            "189/189 [==============================] - 24s 129ms/step - loss: 0.6421 - sparse_categorical_accuracy: 0.7812\n",
            "Epoch 19/50\n",
            " 81/189 [===========>..................] - ETA: 13s - loss: 0.6197 - sparse_categorical_accuracy: 0.7875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cb1688c9e512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awxJj5DyBL3u"
      },
      "source": [
        "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
        "  def __init__(self, temperature = 1, name = None):\n",
        "    super(SupervisedContrastiveLoss, self).__init__(name = name)\n",
        "    self.temperature = temperature\n",
        "\n",
        "  def __call__(self, labels, feature_vectors, sample_weight = None):\n",
        "    # Normalize feature vectors\n",
        "    feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis =1)\n",
        "    #Compute logits\n",
        "    logits = tf.divide(tf.matmul(feature_vectors_normalized, tf.transpose(feature_vectors_normalized)), self.temperature)\n",
        "    return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
        "\n",
        "\n",
        "\n",
        "def add_projection_head(encoder):\n",
        "  inputs = keras.Input(shape = input_shape)\n",
        "  features = encoder(inputs)\n",
        "  outputs = layers.Dense(projection_units, activation='relu')(features)\n",
        "  model = keras.Model(inputs = inputs, outputs = outputs, name = 'cifar-encoder_with_projection-head')\n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "kBdFtFqMDSFe",
        "outputId": "99db26e2-67be-45d3-bde2-3e8bc63431cc"
      },
      "source": [
        "encoder = create_encoder()\n",
        "\n",
        "encoder_with_projection_head = add_projection_head(encoder)\n",
        "encoder_with_projection_head.compile(optimizer = keras.optimizers.Adam(learning_rate),\n",
        "                                     loss= SupervisedContrastiveLoss(temperature))\n",
        "\n",
        "encoder_with_projection_head.summary()\n",
        "\n",
        "history = encoder_with_projection_head.fit(x=x_train, y=y_train, batch_size = batch_size, epochs= num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cifar-encoder_with_projection-head\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "cifar10-encoder (Functional) (None, 2048)              23564807  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "=================================================================\n",
            "Total params: 23,827,079\n",
            "Trainable params: 23,781,632\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "189/189 [==============================] - 29s 130ms/step - loss: 5.3823\n",
            "Epoch 2/50\n",
            "189/189 [==============================] - 26s 136ms/step - loss: 5.1475\n",
            "Epoch 3/50\n",
            "189/189 [==============================] - 25s 132ms/step - loss: 5.0374\n",
            "Epoch 4/50\n",
            "189/189 [==============================] - 25s 131ms/step - loss: 4.9397\n",
            "Epoch 5/50\n",
            "189/189 [==============================] - 25s 133ms/step - loss: 4.8399\n",
            "Epoch 6/50\n",
            "  8/189 [>.............................] - ETA: 25s - loss: 4.7224"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-be98090b8593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mencoder_with_projection_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_with_projection_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDGBYNDlEAtk",
        "outputId": "7b299aef-039c-4d47-dc7c-1962b0f1cfde"
      },
      "source": [
        "classifier = create_classifier(encoder, trainable = False)\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size = batch_size, epochs = num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "189/189 [==============================] - 59s 38ms/step - loss: 1.2805 - sparse_categorical_accuracy: 0.5778\n",
            "Epoch 2/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1663 - sparse_categorical_accuracy: 0.5954\n",
            "Epoch 3/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1509 - sparse_categorical_accuracy: 0.5995\n",
            "Epoch 4/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1519 - sparse_categorical_accuracy: 0.5967\n",
            "Epoch 5/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1354 - sparse_categorical_accuracy: 0.5997\n",
            "Epoch 6/50\n",
            "189/189 [==============================] - 7s 39ms/step - loss: 1.1360 - sparse_categorical_accuracy: 0.6021\n",
            "Epoch 7/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1332 - sparse_categorical_accuracy: 0.6025\n",
            "Epoch 8/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1275 - sparse_categorical_accuracy: 0.6027\n",
            "Epoch 9/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1323 - sparse_categorical_accuracy: 0.6038\n",
            "Epoch 10/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1224 - sparse_categorical_accuracy: 0.6033\n",
            "Epoch 11/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1243 - sparse_categorical_accuracy: 0.6026\n",
            "Epoch 12/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.1273 - sparse_categorical_accuracy: 0.6023\n",
            "Epoch 13/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1310 - sparse_categorical_accuracy: 0.6030\n",
            "Epoch 14/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1274 - sparse_categorical_accuracy: 0.6044\n",
            "Epoch 15/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1242 - sparse_categorical_accuracy: 0.6064\n",
            "Epoch 16/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1179 - sparse_categorical_accuracy: 0.6052\n",
            "Epoch 17/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1217 - sparse_categorical_accuracy: 0.6029\n",
            "Epoch 18/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1241 - sparse_categorical_accuracy: 0.6028\n",
            "Epoch 19/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1269 - sparse_categorical_accuracy: 0.6017\n",
            "Epoch 20/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1188 - sparse_categorical_accuracy: 0.6051\n",
            "Epoch 21/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1252 - sparse_categorical_accuracy: 0.6026\n",
            "Epoch 22/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1163 - sparse_categorical_accuracy: 0.6056\n",
            "Epoch 23/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1185 - sparse_categorical_accuracy: 0.6067\n",
            "Epoch 24/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1148 - sparse_categorical_accuracy: 0.6060\n",
            "Epoch 25/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1210 - sparse_categorical_accuracy: 0.6052\n",
            "Epoch 26/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1165 - sparse_categorical_accuracy: 0.6055\n",
            "Epoch 27/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1150 - sparse_categorical_accuracy: 0.6044\n",
            "Epoch 28/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1207 - sparse_categorical_accuracy: 0.6034\n",
            "Epoch 29/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1110 - sparse_categorical_accuracy: 0.6049\n",
            "Epoch 30/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1211 - sparse_categorical_accuracy: 0.6040\n",
            "Epoch 31/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1208 - sparse_categorical_accuracy: 0.6019\n",
            "Epoch 32/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1203 - sparse_categorical_accuracy: 0.6031\n",
            "Epoch 33/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1176 - sparse_categorical_accuracy: 0.6067\n",
            "Epoch 34/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1181 - sparse_categorical_accuracy: 0.6048\n",
            "Epoch 35/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1130 - sparse_categorical_accuracy: 0.6086\n",
            "Epoch 36/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1158 - sparse_categorical_accuracy: 0.6060\n",
            "Epoch 37/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1162 - sparse_categorical_accuracy: 0.6055\n",
            "Epoch 38/50\n",
            "189/189 [==============================] - 7s 39ms/step - loss: 1.1046 - sparse_categorical_accuracy: 0.6089\n",
            "Epoch 39/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1133 - sparse_categorical_accuracy: 0.6064\n",
            "Epoch 40/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1119 - sparse_categorical_accuracy: 0.6086\n",
            "Epoch 41/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1249 - sparse_categorical_accuracy: 0.6040\n",
            "Epoch 42/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1054 - sparse_categorical_accuracy: 0.6086\n",
            "Epoch 43/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1154 - sparse_categorical_accuracy: 0.6052\n",
            "Epoch 44/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1176 - sparse_categorical_accuracy: 0.6054\n",
            "Epoch 45/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1166 - sparse_categorical_accuracy: 0.6051\n",
            "Epoch 46/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.1128 - sparse_categorical_accuracy: 0.6064\n",
            "Epoch 47/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1136 - sparse_categorical_accuracy: 0.6071\n",
            "Epoch 48/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1142 - sparse_categorical_accuracy: 0.6068\n",
            "Epoch 49/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1182 - sparse_categorical_accuracy: 0.6071\n",
            "Epoch 50/50\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 1.1151 - sparse_categorical_accuracy: 0.6057\n",
            "313/313 [==============================] - 6s 15ms/step - loss: 1.0822 - sparse_categorical_accuracy: 0.6070\n",
            "Test accuracy: 60.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn0U_O4NEh1y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}